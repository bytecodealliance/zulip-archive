<html>
<head><meta charset="utf-8"><title>Performance regression with keep_resident + tables in 35.0.0 · wasmtime · Zulip Chat Archive</title></head>
<h2>Stream: <a href="https://bytecodealliance.github.io/zulip-archive/stream/217126-wasmtime/index.html">wasmtime</a></h2>
<h3>Topic: <a href="https://bytecodealliance.github.io/zulip-archive/stream/217126-wasmtime/topic/Performance.20regression.20with.20keep_resident.20.2B.20tables.20in.2035.2E0.2E0.html">Performance regression with keep_resident + tables in 35.0.0</a></h3>

<hr>

<base href="https://bytecodealliance.zulipchat.com">

<head><link href="https://bytecodealliance.github.io/zulip-archive/style.css" rel="stylesheet"></head>

<a name="535556893"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/217126-wasmtime/topic/Performance%20regression%20with%20keep_resident%20%2B%20tables%20in%2035.0.0/near/535556893" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Alex Crichton <a href="https://bytecodealliance.github.io/zulip-archive/stream/217126-wasmtime/topic/Performance.20regression.20with.20keep_resident.20.2B.20tables.20in.2035.2E0.2E0.html#535556893">(Aug 21 2025 at 18:23)</a>:</h4>
<p>I just finished debugging a performance regression in Spin and wanted to write it down here in case anyone else is affected by this. We were seeing a performance regression when Wasmtime 34 was updated to Wasmtime 35. After various layers of bisection I found that <a href="https://github.com/bytecodealliance/wasmtime/pull/10388">https://github.com/bytecodealliance/wasmtime/pull/10388</a> was the culprit.</p>
<p>The stack-switching PR was disabled for Wasmtime 34 despite merging just before the branch (I reverted it manually to de-risk Wasmtime 34). The PR, however, lives in Wasmtime 35 and 36 and main today. After puzzling over how an off-by-default feature would affect performance so drastically I discovered that the PR inadvertently changed the behavior of <code>TablePool::reset_table_pages_to_zero</code> where previously only the table's size was reset and afterwards the entire table slot was reset. A calculation of <code>table.size() * mem::size_of::&lt;*mut u8&gt;()</code> was changed to <code>self.data_size(table.element_type())</code> where the latter is the size of the whole slot. A normal bug to happen so no one's at fault of course.</p>
<p>This meant, though, that when combined with <code>*_keep_resident</code> options it means that tables could have a way higher memset amount afterwards than before (for the same-size tables too). This ended up being the source of our performance regression.</p>
<p>The reason I'm talking about this here instead of on GitHub is that this is inadvertently already fixed. I ended up fixing this behavior in <a href="https://github.com/bytecodealliance/wasmtime/pull/11341">https://github.com/bytecodealliance/wasmtime/pull/11341</a> mistakenly assuming that the table pool allocator had always reset the entire slot instead of just the table itself. Basically I didn't realize that the behavior I was changing had itself changed recently with the merging of stack-switching. That PR did not make its way into Wasmtime 35 but it has made its way into Wasmtime 36.</p>
<p>So tl;dr; if you use <code>*_keep_resident</code> and see a performance regression on Wasmtime 35 but not 34 or 36 this may be why.</p>
<div class="message_embed"><a class="message_embed_image" href="https://github.com/bytecodealliance/wasmtime/pull/10388" style="background-image: url(&quot;https://uploads.zulipusercontent.net/ae156b502d99e70b41799fcda1a5f96c17e636e9/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f363862623431376134323031303531303261373834336437646131353664343865373535643962343766656164323962333463636331666661626438396332632f62797465636f6465616c6c69616e63652f7761736d74696d652f70756c6c2f3130333838&quot;)"></a><div class="data-container"><div class="message_embed_title"><a href="https://github.com/bytecodealliance/wasmtime/pull/10388" title="Stack switching: Infrastructure and runtime support by frank-emrich · Pull Request #10388 · bytecodealliance/wasmtime">Stack switching: Infrastructure and runtime support by frank-emrich · Pull Request #10388 · bytecodealliance/wasmtime</a></div><div class="message_embed_description">This PR is part of a series that adds support for the Wasm stack switching proposal. The explainer document for the proposal is here. There&#39;s a tracking issue describing the overall progress an...</div></div></div><div class="message_embed"><a class="message_embed_image" href="https://github.com/bytecodealliance/wasmtime/pull/11341" style="background-image: url(&quot;https://uploads.zulipusercontent.net/10b832be8dd81af42279e0f142440e039016908a/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f383563626466666432336465336437626439663064656330363835646139323635366539373661623164396265623537646633366561303562343161316562332f62797465636f6465616c6c69616e63652f7761736d74696d652f70756c6c2f3131333431&quot;)"></a><div class="data-container"><div class="message_embed_title"><a href="https://github.com/bytecodealliance/wasmtime/pull/11341" title="Reset fewer bytes when resetting tables by alexcrichton · Pull Request #11341 · bytecodealliance/wasmtime">Reset fewer bytes when resetting tables by alexcrichton · Pull Request #11341 · bytecodealliance/wasmtime</a></div><div class="message_embed_description">This commit changes the resetting of tables back to all-null in TablePool::reset_table_pages_to_zero. Previously the full capacity of the table was reset back to zero, depending on the configuratio...</div></div></div>



<a name="536668438"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/217126-wasmtime/topic/Performance%20regression%20with%20keep_resident%20%2B%20tables%20in%2035.0.0/near/536668438" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paul Osborne <a href="https://bytecodealliance.github.io/zulip-archive/stream/217126-wasmtime/topic/Performance.20regression.20with.20keep_resident.20.2B.20tables.20in.2035.2E0.2E0.html#536668438">(Aug 28 2025 at 19:04)</a>:</h4>
<p>Interesting, thanks for finding this and for the writeup; that's definitely an error I made while working to address feedback on the stack-switching runtime changes.</p>



<a name="536804579"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/217126-wasmtime/topic/Performance%20regression%20with%20keep_resident%20%2B%20tables%20in%2035.0.0/near/536804579" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Roman Volosatovs <a href="https://bytecodealliance.github.io/zulip-archive/stream/217126-wasmtime/topic/Performance.20regression.20with.20keep_resident.20.2B.20tables.20in.2035.2E0.2E0.html#536804579">(Aug 29 2025 at 14:45)</a>:</h4>
<p>That likely explains this profile I've seen on Wasmtime 35 with <code>keep_resident</code> options set <a href="https://profiler.firefox.com/public/8zfwkxghrmkz4d4bzd6zb9famgrx76kdw617bw0/flame-graph/?globalTrackOrder=102&amp;hiddenGlobalTracks=02&amp;symbolServer=http%3A%2F%2F127.0.0.1%3A3333%2F3nc2077n82dr7b772r2b9l8vm41mhn9anasg47j&amp;thread=2whswxpxrwzmzowAlAnwCiCkwDhDjwFeFgwGdGfwIb&amp;transforms=f-combined-gwkx8wxbxdxeyuyvz3z4&amp;v=11">https://profiler.firefox.com/public/8zfwkxghrmkz4d4bzd6zb9famgrx76kdw617bw0/flame-graph/?globalTrackOrder=102&amp;hiddenGlobalTracks=02&amp;symbolServer=http%3A%2F%2F127.0.0.1%3A3333%2F3nc2077n82dr7b772r2b9l8vm41mhn9anasg47j&amp;thread=2whswxpxrwzmzowAlAnwCiCkwDhDjwFeFgwGdGfwIb&amp;transforms=f-combined-gwkx8wxbxdxeyuyvz3z4&amp;v=11</a></p>
<p>I've removed these options to work around it, but maybe I should revisit them in 36</p>



<a name="536804967"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/217126-wasmtime/topic/Performance%20regression%20with%20keep_resident%20%2B%20tables%20in%2035.0.0/near/536804967" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Alex Crichton <a href="https://bytecodealliance.github.io/zulip-archive/stream/217126-wasmtime/topic/Performance.20regression.20with.20keep_resident.20.2B.20tables.20in.2035.2E0.2E0.html#536804967">(Aug 29 2025 at 14:47)</a>:</h4>
<p>Your profile Roman shows most of the memset from <code>deallocate_memories</code> which shouldn't have changed between 34/35/36, so that may be something else?</p>



<a name="536806163"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/217126-wasmtime/topic/Performance%20regression%20with%20keep_resident%20%2B%20tables%20in%2035.0.0/near/536806163" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Roman Volosatovs <a href="https://bytecodealliance.github.io/zulip-archive/stream/217126-wasmtime/topic/Performance.20regression.20with.20keep_resident.20.2B.20tables.20in.2035.2E0.2E0.html#536806163">(Aug 29 2025 at 14:54)</a>:</h4>
<p>In that embedding the memory size is actually static across all modules, and it's pretty big, so I just assumed that it's simply too big for the feature. <code>madvise</code> performed way better in my testing.<br>
I did see the table deallocation also incur significant cost, but I've since lost that profile - removing the <code>keep_resident</code> options fixed both issues for me that time.</p>
<p>for reference, here's the complete set of config I landed upon in the end: <a href="https://github.com/near/nearcore/blob/359902578a29d4542fb0d816c9cee2a45341d4a0/runtime/near-vm-runner/src/wasmtime_runner/mod.rs#L353-L414">https://github.com/near/nearcore/blob/359902578a29d4542fb0d816c9cee2a45341d4a0/runtime/near-vm-runner/src/wasmtime_runner/mod.rs#L353-L414</a></p>
<div class="message_embed"><a class="message_embed_image" href="https://github.com/near/nearcore/blob/359902578a29d4542fb0d816c9cee2a45341d4a0/runtime/near-vm-runner/src/wasmtime_runner/mod.rs#L353-L414" style="background-image: url(&quot;https://uploads.zulipusercontent.net/95141b1983b26291542bb02ad4acfe5bd2097a39/68747470733a2f2f7265706f7369746f72792d696d616765732e67697468756275736572636f6e74656e742e636f6d2f3135313333313933382f62306363386638302d306434362d313165622d393435302d376435643465313865353466&quot;)"></a><div class="data-container"><div class="message_embed_title"><a href="https://github.com/near/nearcore/blob/359902578a29d4542fb0d816c9cee2a45341d4a0/runtime/near-vm-runner/src/wasmtime_runner/mod.rs#L353-L414" title="nearcore/runtime/near-vm-runner/src/wasmtime_runner/mod.rs at 359902578a29d4542fb0d816c9cee2a45341d4a0 · near/nearcore">nearcore/runtime/near-vm-runner/src/wasmtime_runner/mod.rs at 359902578a29d4542fb0d816c9cee2a45341d4a0 · near/nearcore</a></div><div class="message_embed_description">Reference client for NEAR Protocol. Contribute to near/nearcore development by creating an account on GitHub.</div></div></div>



<a name="536806397"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/217126-wasmtime/topic/Performance%20regression%20with%20keep_resident%20%2B%20tables%20in%2035.0.0/near/536806397" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Roman Volosatovs <a href="https://bytecodealliance.github.io/zulip-archive/stream/217126-wasmtime/topic/Performance.20regression.20with.20keep_resident.20.2B.20tables.20in.2035.2E0.2E0.html#536806397">(Aug 29 2025 at 14:55)</a>:</h4>
<p>at one point I've updated to 36 and it gave some performance benefits</p>



<a name="536829239"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/217126-wasmtime/topic/Performance%20regression%20with%20keep_resident%20%2B%20tables%20in%2035.0.0/near/536829239" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Paul Osborne <a href="https://bytecodealliance.github.io/zulip-archive/stream/217126-wasmtime/topic/Performance.20regression.20with.20keep_resident.20.2B.20tables.20in.2035.2E0.2E0.html#536829239">(Aug 29 2025 at 16:58)</a>:</h4>
<p>I would definitely expect that for certain workloads keep_resident can make things worse, with or without the bug (though worse with the 35 bug).  This is true with the pagemap optimizations as well.  The biggest penalty moves a bit with madvise to arise during page faults, but if there's very few dirtied pages then both the madvise and the page faults can be, in aggregate, pretty expensive.</p>
<p>I did some comparisons of those tradeoffs in comments I added later to <a href="https://github.com/bytecodealliance/wasmtime/pull/11372">https://github.com/bytecodealliance/wasmtime/pull/11372</a>.  What I don't show there is any comparison of a single huge madvise compared against a pagemap scan + madvise.  I felt it reached the point where just trying to bench real workloads made more sense.</p>
<div class="message_embed"><a class="message_embed_image" href="https://github.com/bytecodealliance/wasmtime/pull/11372" style="background-image: url(&quot;https://uploads.zulipusercontent.net/47ff227b8a4c951b7c35239dfb1056a3f319ac14/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f623361396135626161333030633664386266373631313966373537356632643933376638636461653565616333373437633164316162393433353062626330322f62797465636f6465616c6c69616e63652f7761736d74696d652f70756c6c2f3131333732&quot;)"></a><div class="data-container"><div class="message_embed_title"><a href="https://github.com/bytecodealliance/wasmtime/pull/11372" title="Add support for the Linux PAGEMAP_SCAN ioctl by alexcrichton · Pull Request #11372 · bytecodealliance/wasmtime">Add support for the Linux PAGEMAP_SCAN ioctl by alexcrichton · Pull Request #11372 · bytecodealliance/wasmtime</a></div><div class="message_embed_description">This series of commits is the brainchild of @tschneidereit who, in his spare time, reads Linux kernel documentation and finds random ioctls. Specifically @tschneidereit discovered the PAGEMAP_SCAN ...</div></div></div>



<hr><p>Last updated: Oct 25 2025 at 23:03 UTC</p>
</html>