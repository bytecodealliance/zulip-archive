[
    {
        "content": "<p>Hi! I've recently hit some unimplemented SIMD operations, such as <code>fmul</code> with <code>f32x2</code> on x64 (<code>should be implemented in ISLE</code>), and I'm wondering how exactly I should deal with it. </p>\n<p>I thought about extending my value to a <code>f32x4</code>, but I don't see any instruction that would allow me to easily do that except, maybe, <code>insertlane</code> and <code>extractlane</code>, but I'm worried this would hurt codegen &amp; performance. Is this really the way to go about it?</p>\n<p>I've also considered implementing these lowerings, but I've never contributed to cranelift and don't know how much work that would be. If this is an approachable issue, I'd happily contribute.</p>",
        "id": 566005656,
        "sender_full_name": "vx",
        "timestamp": 1767310762
    },
    {
        "content": "<p>Hi <span class=\"user-mention\" data-user-id=\"996593\">@vx</span> -- those are indeed the two general approaches (widen to 128 bit or fill out the 64-bit lowerings in Cranelift). The former is probably actually pretty reasonable performance-wise as long as you can keep data in registers most of the time -- the widening/narrowing will happen whenever you store/load from your native narrow-vector format only, and the nature of SIMD is that all lanes go independently at the same time so the extra lanes can just be \"don't care\" bits and won't slow things down.</p>\n<p>Ideally we'd also fill out narrow-SIMD lowerings, but that's a big project. IIRC the 64-bit SIMD stuff was originally put in place for aarch64 because it supports these variants, but other ISAs may not, so we effectively need the equivalent of widening/narrowing at the instruction selection level (at least where interfacing with memory via loads/stores) anyway.</p>",
        "id": 566074818,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1767370415
    }
]