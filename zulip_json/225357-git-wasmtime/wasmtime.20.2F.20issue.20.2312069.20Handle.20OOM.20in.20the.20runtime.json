[
    {
        "content": "<p>fitzgen opened <a href=\"https://github.com/bytecodealliance/wasmtime/issues/12069\">issue #12069</a>:</p>\n<blockquote>\n<p>We have been discussing this in a couple recent Wasmtime meetings[^0] and <a href=\"#narrow/channel/217126-wasmtime/topic/OOM.20handling.20in.20.28parts.20of.29.20Wasmtime\">on Zulip</a> and I figured it was time to centralize discussion in a tracking issue.</p>\n<p>[^0]: See <a href=\"https://github.com/bytecodealliance/meetings/blob/main/wasmtime/2025/wasmtime-10-23.md\">https://github.com/bytecodealliance/meetings/blob/main/wasmtime/2025/wasmtime-10-23.md</a> and <a href=\"https://github.com/bytecodealliance/meetings/blob/main/wasmtime/2025/wasmtime-11-20.md\">https://github.com/bytecodealliance/meetings/blob/main/wasmtime/2025/wasmtime-11-20.md</a></p>\n<p>What does handling OOM mean in this case? It means turning allocation failure into an <code>Err(...)</code> return and ultimately propagating that up to the Wasmtime embedder. It may even involve poisoning various data structures if necessary, maybe up to a whole store if necessary, but we haven't fleshed out the details completely yet. That will happen in discussions on this issue and various PRs during implementation.</p>\n<p>Various, unordered sketches of things that will be involved:</p>\n<ul>\n<li>[ ] Replace <code>anyhow::Error</code> with a custom <code>wasmtime::Error</code>. At its most bare-bones, with all cargo features disabled, we will want this to basically be an <code>enum</code> without any data payloads in its variants. As we enable more cargo features, we can start adding support for formatting and error context and ultimately get to something like <code>anyhow::Error</code> with all features enabled.</li>\n<li>[ ] Create a <code>wasmtime-collections</code> crate that exposes fallible <code>Vec</code>, <code>HashMap</code>, etc... This is probably just going to be newtypes over the types we already use today, but <code>wasmtime_collections::Vec::push</code> will return a <code>Result</code> and be implemented via something like <code>self.0.try_reserve(1)?; self.0.push(item); Ok(())</code>, for example.</li>\n<li>[ ] We will need custom <code>serde::Deserialize</code> implementations that handle OOM failure for the <code>wasmtime-collections</code> types we use in our metadata that gets serialized into elf sections in our compiled code.</li>\n<li>[ ] We would ideally like to statically analyze our code and make sure that we aren't allocating infallibly in the relevant code paths. It seems like we can probably use clippy for this, or at least for a 95% solution to this that is Good Enough in practice.</li>\n<li>[ ] We need a way to dynamically test/fuzz our OOM handling to make sure we are actually getting it right in practice.</li>\n</ul>\n<p>We will initially focus on supporting the following code paths:</p>\n<ul>\n<li>Creating a <code>Config</code></li>\n<li>Creating an <code>Engine</code></li>\n<li>Creating a <code>Linker</code></li>\n<li>Creating <code>InstancePre</code>s</li>\n<li>Deserializing pre-compiled <code>Module</code>s and <code>Component</code>s (<em>not</em> compiling new ones!)</li>\n<li>Creating <code>Store</code>s</li>\n<li>Creating <code>Instance</code>s</li>\n<li>Creating <code>Memory</code>s, <code>Table</code>s, <code>Global</code>s, etc...</li>\n<li>Running Wasm</li>\n</ul>\n<p>Basically, everything that is supported in our no-std/pulley builds now: a basic runtime without the compiler, that can only run pre-compiled Wasm. We will not initially support async or the pooling allocator either, for example. I have vague ideas about how we might be able to refactor the pooling allocator for greater flexibility and enable its use in no-std / no-virtual-memory environments, but that is a bit orthogonal.</p>\n<p>Eventually we will want to support async Wasm, yielding on out-of-fuel, ..., and the component model's async functionality. That is going to be a larger project on top of this already large project, so I'm going to delay talking about how we will cross that bridge until we get closer to it.</p>\n<p>In practice, I expect that we will start with the OOM testing/fuzzing, create something very simple that fails immediately, and land that as \"expected to fail\". Then we can get that passing, which will be quite a bunch of work for this first iteration. Then we can remove the failure expectation. Then we can do a little bit more stuff inside the OOM testing/fuzzing and reveal new places we need to fix, and then we can fix those. We can continue this process until things are starting to look more and more complete. At some point we will add the clippy lints, initially to smaller modules and eventually to bigger regions of code. But the testing can be the forcing function for what area of code we add OOM handling to each step of the way.</p>\n<p>The best way to dynamically test/fuzz OOM handling that I know of is <a href=\"https://firefox-source-docs.mozilla.org/js/hacking_tips.html#how-to-debug-oomtest-failures\">the approach taken by SpiderMonkey's <code>oomTest()</code> helper</a>: run a piece of code (potentially written by humans or generated by a fuzzer) with a special allocator that will return null on the first allocation made and check that the code didn't fail to handle the OOM, then run that code again but failing on the second allocation, then the third, etc... up to your time/compute budget. Starting by building this infrastructure is my rough plan. I've done a little bit of digging for other approaches to ensuring that your OOM-handling is correct, and I haven't really found anything, just people arguing about whether you should even check for null returns from <code>malloc</code> or not, which is not very helpful. That is to say, if anyone has any other ideas or knows of any other prior art here, I'd love to hear about it!</p>\n</blockquote>",
        "id": 558743369,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1763755666
    },
    {
        "content": "<p><a href=\"https://github.com/fitzgen\">fitzgen</a> added the wasmtime:platform-support label to <a href=\"https://github.com/bytecodealliance/wasmtime/issues/12069\">Issue #12069</a>.</p>",
        "id": 558743371,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1763755667
    },
    {
        "content": "<p>bjorn3 <a href=\"https://github.com/bytecodealliance/wasmtime/issues/12069#issuecomment-3564570910\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/12069\">issue #12069</a>:</p>\n<blockquote>\n<p>I suspect you are going to have a hard time ensuring that all dependencies can also handle OOM. For example for parsing ELF files you are using the object crate which allocates. Symbolizing backtraces allocates a debuginfo cache. async-trait allocates boxes for all futures. Serde allocates (and I don't think it is possible to support handling OOM in there without making an api breaking change)</p>\n<p>The unstable <code>std::alloc::set_alloc_error_hook</code> would almost certainly be much easier to use. It is unstable pending a decision if unwinding out of it would be allowed though and if we should even allow running user code on <code>handle_alloc_error</code>. (the argument for not allowing it is that there may be unsafe code that is unsound under the extra reentrancy that this would allow)</p>\n</blockquote>",
        "id": 558750081,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1763758711
    },
    {
        "content": "<p>bjorn3 edited a <a href=\"https://github.com/bytecodealliance/wasmtime/issues/12069#issuecomment-3564570910\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/12069\">issue #12069</a>:</p>\n<blockquote>\n<p>I suspect you are going to have a hard time ensuring that all dependencies can also handle OOM. For example for parsing ELF files you are using the object crate which allocates. Symbolizing backtraces allocates a debuginfo cache. async-trait allocates boxes for all futures. Serde allocates when deserializing common types like <code>Vec</code> (and I don't think it is possible to support handling OOM in there without making an api breaking change)</p>\n<p>The unstable <code>std::alloc::set_alloc_error_hook</code> would almost certainly be much easier to use. It is unstable pending a decision if unwinding out of it would be allowed though and if we should even allow running user code on <code>handle_alloc_error</code>. (the argument for not allowing it is that there may be unsafe code that is unsound under the extra reentrancy that this would allow)</p>\n</blockquote>",
        "id": 558750228,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1763758782
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/12069#issuecomment-3564591091\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/12069\">issue #12069</a>:</p>\n<blockquote>\n<p>@bjorn3 thanks for the thoughts; we have thought pretty extensively about this and we think the unwinding-based approach is probably not viable in our no-std embedding (see Zulip thread that Nick linked for more). Nick covered serde above; we can turn off symbolization in our embedding; boxed futures are going to be a big hassle when we get to async but in principle there should be ways to define enough of our own version of dependencies to make this work.</p>\n</blockquote>",
        "id": 558751284,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1763759240
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/issues/12069#issuecomment-3564623419\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/12069\">issue #12069</a>:</p>\n<blockquote>\n<p>Personally I view this direction for Wasmtime as a high-level decision point for the project. On one hand we have a proposal like @fitzgen has laid out where the pros are \"highly portable\" and the cons are \"big changes, unknown impact on maintainabiilty\". On the other hand could go the route of something like <code>set_alloc_error_hook</code> and/or unwinding which inverts the pros/cons here a bit -- e.g. few changes but much less portable.</p>\n<p>In my opinion it's worthwhile to shoot for the more portable version of things. We can all agree it's going to be a big chunk of work, but the portability of such a solution is highly attractive I believe. I'm also somewhat confident that we can thread the needle on the maintainability and runtime cost of this solution so I'm less worried about that.</p>\n<p>If, however, the strategy of \"check for oom everywhere\" doesn't work out then we can go back to the drawing board and think harder about unwinding perhaps, but in lieu of that I'd like to pull on the design thread @fitzgen is proposing here and see how far it gets us.</p>\n</blockquote>",
        "id": 558752854,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1763759989
    },
    {
        "content": "<p>bjorn3 <a href=\"https://github.com/bytecodealliance/wasmtime/issues/12069#issuecomment-3564663572\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/12069\">issue #12069</a>:</p>\n<blockquote>\n<p>I'm afraid you will have to basically forego like half of all wasmtime dependencies and write replacements for them. (I wrote this before I did the inventarization below. turns out I was pretty much spot on. 20 allocating vs 18 non-allocating)</p>\n<p>With <code>cargo check --no-default-features --features \"runtime async component-model component-model-async stack-switching\"</code> I'm getting the following runtime dependencies (checked means likely unconditionally allocates) excluding Wasmtime controlled ones:</p>\n<ul>\n<li>[x] anyhow</li>\n<li>[ ] bitflags</li>\n<li>[x] bumpalo</li>\n<li>[ ] cfg_if</li>\n<li>[ ] cobs</li>\n<li>[ ] encoding_rs</li>\n<li>[ ] equivalent</li>\n<li>[ ] foldhash</li>\n<li>[ ] futures</li>\n<li>[x] futures_channel</li>\n<li>[ ] futures_core</li>\n<li>[ ] futures_io</li>\n<li>[ ] futures_sink</li>\n<li>[ ] futures_task</li>\n<li>[ ] futures_util</li>\n<li>[x] gimli</li>\n<li>[x] hashbrown</li>\n<li>[x] indexmap</li>\n<li>[ ] libc</li>\n<li>[ ] libm</li>\n<li>[ ] linux_raw_sys</li>\n<li>[ ] log</li>\n<li>[ ] memchr</li>\n<li>[x] memfd (through rustix)</li>\n<li>[x] object (unless limiting yourself to the few apis that don't)</li>\n<li>[ ] once_cell</li>\n<li>[ ] pin_project_lite</li>\n<li>[ ] pin_utils</li>\n<li>[x] postcard (if serde impls do)</li>\n<li>[x] rustix (allocates C string for filename)</li>\n<li>[x] semver</li>\n<li>[x] serde (unless deserializing into types that handle OOM)</li>\n<li>[x] serde_core (unless deserializing into types that handle OOM)</li>\n<li>[x] slab</li>\n<li>[x] smallvec</li>\n<li>[x] target_lexicon</li>\n<li>[x] thiserror</li>\n<li>[x] wasmparser (validator uses <code>Arc</code>, bunch of other things also allocate)</li>\n</ul>\n</blockquote>",
        "id": 558754848,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1763760963
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/12069#issuecomment-3564689735\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/12069\">issue #12069</a>:</p>\n<blockquote>\n<p>@bjorn3 thanks for this analysis. Most of these we have answers to already, I think.</p>\n<ul>\n<li>Nick covered anyhow above. (Replace our error types with non-allocating versions, and layer allocations for backtraces and error messages on top.)</li>\n<li>We control bumpalo (it's Nick's crate) but I suspect its uses fall in the same bucket as \"data structures in general\" for which we have the plan with the wasmtime-specific collection.</li>\n<li>Futures-related crates: yes, we'll need to build fallible-boxing versions of futures abstractions.</li>\n<li>gimli: we can forego all backtracing and native-debug support in the OOM-friendly build.</li>\n<li>hashbrown, indexmap: data structures, plan above.</li>\n<li>memfd: in our no-std environment we don't use memfd (or any Linux abstractions).</li>\n<li>object: yes, we'll need to ensure we have fallible allocation paths.</li>\n<li>postcard: Nick looked into this in the Zulip thread.</li>\n<li>rustix: N/A (no-std build)</li>\n<li>semver: I suspect our uses of this are relatively scoped (module version checks?) and we can probably either stub out or fix semver?</li>\n<li>serde, serde_core: see Zulip thread; custom containers</li>\n<li>slab, smallvec: custom data structures</li>\n<li>target_lexicon: we (BA) control this and can fix if needed</li>\n<li>thiserror: see story for error messages above</li>\n<li>wasmparser: compilation is not within scope</li>\n</ul>\n<p>Basically: yes, it will be expensive. But in the context we (Nick and I at least) are employed to use Wasmtime, we <em>need</em> to be OOM-friendly to continue using Wasmtime at all, and we likely cannot make unwind work easily (and we would not want its complexity in the critical path of a possibly-frequent failure mode in high-traffic scenarios), so it will take more than \"this might be a lot of work\" to convince us otherwise.</p>\n</blockquote>",
        "id": 558755987,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1763761603
    },
    {
        "content": "<p>Soto-J <a href=\"https://github.com/bytecodealliance/wasmtime/issues/12069#issuecomment-3573624377\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/12069\">issue #12069</a>:</p>\n<blockquote>\n<p>Hi! I’m interested in contributing to this effort and would love to help with the OOM-handling work.<br>\nIf there are any recommended starting points or areas that would be most helpful for a new contributor, I’m happy to take them on.</p>\n</blockquote>",
        "id": 560060620,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1764040720
    },
    {
        "content": "<p>fitzgen edited <a href=\"https://github.com/bytecodealliance/wasmtime/issues/12069\">issue #12069</a>:</p>\n<blockquote>\n<p>We have been discussing this in a couple recent Wasmtime meetings[^0] and <a href=\"#narrow/channel/217126-wasmtime/topic/OOM.20handling.20in.20.28parts.20of.29.20Wasmtime\">on Zulip</a> and I figured it was time to centralize discussion in a tracking issue.</p>\n<p>[^0]: See <a href=\"https://github.com/bytecodealliance/meetings/blob/main/wasmtime/2025/wasmtime-10-23.md\">https://github.com/bytecodealliance/meetings/blob/main/wasmtime/2025/wasmtime-10-23.md</a> and <a href=\"https://github.com/bytecodealliance/meetings/blob/main/wasmtime/2025/wasmtime-11-20.md\">https://github.com/bytecodealliance/meetings/blob/main/wasmtime/2025/wasmtime-11-20.md</a></p>\n<p>What does handling OOM mean in this case? It means turning allocation failure into an <code>Err(...)</code> return and ultimately propagating that up to the Wasmtime embedder. It may even involve poisoning various data structures if necessary, maybe up to a whole store if necessary, but we haven't fleshed out the details completely yet. That will happen in discussions on this issue and various PRs during implementation.</p>\n<p>Various, unordered sketches of things that will be involved:</p>\n<ul>\n<li>[x] Replace <code>anyhow::Error</code> with a custom <code>wasmtime::Error</code>. At its most bare-bones, with all cargo features disabled, we will want this to basically be an <code>enum</code> without any data payloads in its variants. As we enable more cargo features, we can start adding support for formatting and error context and ultimately get to something like <code>anyhow::Error</code> with all features enabled.</li>\n<li>[ ] Create a <code>wasmtime-collections</code> crate that exposes fallible <code>Vec</code>, <code>HashMap</code>, etc... This is probably just going to be newtypes over the types we already use today, but <code>wasmtime_collections::Vec::push</code> will return a <code>Result</code> and be implemented via something like <code>self.0.try_reserve(1)?; self.0.push(item); Ok(())</code>, for example.</li>\n<li>[ ] We will need custom <code>serde::Deserialize</code> implementations that handle OOM failure for the <code>wasmtime-collections</code> types we use in our metadata that gets serialized into elf sections in our compiled code.</li>\n<li>[ ] We would ideally like to statically analyze our code and make sure that we aren't allocating infallibly in the relevant code paths. It seems like we can probably use clippy for this, or at least for a 95% solution to this that is Good Enough in practice.</li>\n<li>[ ] We need a way to dynamically test/fuzz our OOM handling to make sure we are actually getting it right in practice.</li>\n</ul>\n<p>We will initially focus on supporting the following code paths:</p>\n<ul>\n<li>Creating a <code>Config</code></li>\n<li>Creating an <code>Engine</code></li>\n<li>Creating a <code>Linker</code></li>\n<li>Creating <code>InstancePre</code>s</li>\n<li>Deserializing pre-compiled <code>Module</code>s and <code>Component</code>s (<em>not</em> compiling new ones!)</li>\n<li>Creating <code>Store</code>s</li>\n<li>Creating <code>Instance</code>s</li>\n<li>Creating <code>Memory</code>s, <code>Table</code>s, <code>Global</code>s, etc...</li>\n<li>Running Wasm</li>\n</ul>\n<p>Basically, everything that is supported in our no-std/pulley builds now: a basic runtime without the compiler, that can only run pre-compiled Wasm. We will not initially support async or the pooling allocator either, for example. I have vague ideas about how we might be able to refactor the pooling allocator for greater flexibility and enable its use in no-std / no-virtual-memory environments, but that is a bit orthogonal.</p>\n<p>Eventually we will want to support async Wasm, yielding on out-of-fuel, ..., and the component model's async functionality. That is going to be a larger project on top of this already large project, so I'm going to delay talking about how we will cross that bridge until we get closer to it.</p>\n<p>In practice, I expect that we will start with the OOM testing/fuzzing, create something very simple that fails immediately, and land that as \"expected to fail\". Then we can get that passing, which will be quite a bunch of work for this first iteration. Then we can remove the failure expectation. Then we can do a little bit more stuff inside the OOM testing/fuzzing and reveal new places we need to fix, and then we can fix those. We can continue this process until things are starting to look more and more complete. At some point we will add the clippy lints, initially to smaller modules and eventually to bigger regions of code. But the testing can be the forcing function for what area of code we add OOM handling to each step of the way.</p>\n<p>The best way to dynamically test/fuzz OOM handling that I know of is <a href=\"https://firefox-source-docs.mozilla.org/js/hacking_tips.html#how-to-debug-oomtest-failures\">the approach taken by SpiderMonkey's <code>oomTest()</code> helper</a>: run a piece of code (potentially written by humans or generated by a fuzzer) with a special allocator that will return null on the first allocation made and check that the code didn't fail to handle the OOM, then run that code again but failing on the second allocation, then the third, etc... up to your time/compute budget. Starting by building this infrastructure is my rough plan. I've done a little bit of digging for other approaches to ensuring that your OOM-handling is correct, and I haven't really found anything, just people arguing about whether you should even check for null returns from <code>malloc</code> or not, which is not very helpful. That is to say, if anyone has any other ideas or knows of any other prior art here, I'd love to hear about it!</p>\n</blockquote>",
        "id": 568079177,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1768424353
    },
    {
        "content": "<p>fitzgen edited <a href=\"https://github.com/bytecodealliance/wasmtime/issues/12069\">issue #12069</a>:</p>\n<blockquote>\n<p>We have been discussing this in a couple recent Wasmtime meetings[^0] and <a href=\"#narrow/channel/217126-wasmtime/topic/OOM.20handling.20in.20.28parts.20of.29.20Wasmtime\">on Zulip</a> and I figured it was time to centralize discussion in a tracking issue.</p>\n<p>[^0]: See <a href=\"https://github.com/bytecodealliance/meetings/blob/main/wasmtime/2025/wasmtime-10-23.md\">https://github.com/bytecodealliance/meetings/blob/main/wasmtime/2025/wasmtime-10-23.md</a> and <a href=\"https://github.com/bytecodealliance/meetings/blob/main/wasmtime/2025/wasmtime-11-20.md\">https://github.com/bytecodealliance/meetings/blob/main/wasmtime/2025/wasmtime-11-20.md</a></p>\n<p>What does handling OOM mean in this case? It means turning allocation failure into an <code>Err(...)</code> return and ultimately propagating that up to the Wasmtime embedder. It may even involve poisoning various data structures if necessary, maybe up to a whole store if necessary, but we haven't fleshed out the details completely yet. That will happen in discussions on this issue and various PRs during implementation.</p>\n<p>Various, unordered sketches of things that will be involved:</p>\n<ul>\n<li>[x] Replace <code>anyhow::Error</code> with a custom <code>wasmtime::Error</code>. At its most bare-bones, with all cargo features disabled, we will want this to basically be an <code>enum</code> without any data payloads in its variants. As we enable more cargo features, we can start adding support for formatting and error context and ultimately get to something like <code>anyhow::Error</code> with all features enabled.</li>\n<li>[x] Create a <code>wasmtime-collections</code> crate that exposes fallible <code>Vec</code>, <code>HashMap</code>, etc... This is probably just going to be newtypes over the types we already use today, but <code>wasmtime_collections::Vec::push</code> will return a <code>Result</code> and be implemented via something like <code>self.0.try_reserve(1)?; self.0.push(item); Ok(())</code>, for example.</li>\n<li>[ ] We will need custom <code>serde::Deserialize</code> implementations that handle OOM failure for the <code>wasmtime-collections</code> types we use in our metadata that gets serialized into elf sections in our compiled code.</li>\n<li>[ ] We would ideally like to statically analyze our code and make sure that we aren't allocating infallibly in the relevant code paths. It seems like we can probably use clippy for this, or at least for a 95% solution to this that is Good Enough in practice.</li>\n<li>[ ] We need a way to dynamically test/fuzz our OOM handling to make sure we are actually getting it right in practice.</li>\n</ul>\n<p>We will initially focus on supporting the following code paths:</p>\n<ul>\n<li>Creating a <code>Config</code></li>\n<li>Creating an <code>Engine</code></li>\n<li>Creating a <code>Linker</code></li>\n<li>Creating <code>InstancePre</code>s</li>\n<li>Deserializing pre-compiled <code>Module</code>s and <code>Component</code>s (<em>not</em> compiling new ones!)</li>\n<li>Creating <code>Store</code>s</li>\n<li>Creating <code>Instance</code>s</li>\n<li>Creating <code>Memory</code>s, <code>Table</code>s, <code>Global</code>s, etc...</li>\n<li>Running Wasm</li>\n</ul>\n<p>Basically, everything that is supported in our no-std/pulley builds now: a basic runtime without the compiler, that can only run pre-compiled Wasm. We will not initially support async or the pooling allocator either, for example. I have vague ideas about how we might be able to refactor the pooling allocator for greater flexibility and enable its use in no-std / no-virtual-memory environments, but that is a bit orthogonal.</p>\n<p>Eventually we will want to support async Wasm, yielding on out-of-fuel, ..., and the component model's async functionality. That is going to be a larger project on top of this already large project, so I'm going to delay talking about how we will cross that bridge until we get closer to it.</p>\n<p>In practice, I expect that we will start with the OOM testing/fuzzing, create something very simple that fails immediately, and land that as \"expected to fail\". Then we can get that passing, which will be quite a bunch of work for this first iteration. Then we can remove the failure expectation. Then we can do a little bit more stuff inside the OOM testing/fuzzing and reveal new places we need to fix, and then we can fix those. We can continue this process until things are starting to look more and more complete. At some point we will add the clippy lints, initially to smaller modules and eventually to bigger regions of code. But the testing can be the forcing function for what area of code we add OOM handling to each step of the way.</p>\n<p>The best way to dynamically test/fuzz OOM handling that I know of is <a href=\"https://firefox-source-docs.mozilla.org/js/hacking_tips.html#how-to-debug-oomtest-failures\">the approach taken by SpiderMonkey's <code>oomTest()</code> helper</a>: run a piece of code (potentially written by humans or generated by a fuzzer) with a special allocator that will return null on the first allocation made and check that the code didn't fail to handle the OOM, then run that code again but failing on the second allocation, then the third, etc... up to your time/compute budget. Starting by building this infrastructure is my rough plan. I've done a little bit of digging for other approaches to ensuring that your OOM-handling is correct, and I haven't really found anything, just people arguing about whether you should even check for null returns from <code>malloc</code> or not, which is not very helpful. That is to say, if anyone has any other ideas or knows of any other prior art here, I'd love to hear about it!</p>\n</blockquote>",
        "id": 569814686,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1769208835
    },
    {
        "content": "<p>fitzgen edited <a href=\"https://github.com/bytecodealliance/wasmtime/issues/12069\">issue #12069</a>:</p>\n<blockquote>\n<p>We have been discussing this in a couple recent Wasmtime meetings[^0] and <a href=\"#narrow/channel/217126-wasmtime/topic/OOM.20handling.20in.20.28parts.20of.29.20Wasmtime\">on Zulip</a> and I figured it was time to centralize discussion in a tracking issue.</p>\n<p>[^0]: See <a href=\"https://github.com/bytecodealliance/meetings/blob/main/wasmtime/2025/wasmtime-10-23.md\">https://github.com/bytecodealliance/meetings/blob/main/wasmtime/2025/wasmtime-10-23.md</a> and <a href=\"https://github.com/bytecodealliance/meetings/blob/main/wasmtime/2025/wasmtime-11-20.md\">https://github.com/bytecodealliance/meetings/blob/main/wasmtime/2025/wasmtime-11-20.md</a></p>\n<p>What does handling OOM mean in this case? It means turning allocation failure into an <code>Err(...)</code> return and ultimately propagating that up to the Wasmtime embedder. It may even involve poisoning various data structures if necessary, maybe up to a whole store if necessary, but we haven't fleshed out the details completely yet. That will happen in discussions on this issue and various PRs during implementation.</p>\n<p>Various, unordered sketches of things that will be involved:</p>\n<ul>\n<li>[x] Replace <code>anyhow::Error</code> with a custom <code>wasmtime::Error</code>. At its most bare-bones, with all cargo features disabled, we will want this to basically be an <code>enum</code> without any data payloads in its variants. As we enable more cargo features, we can start adding support for formatting and error context and ultimately get to something like <code>anyhow::Error</code> with all features enabled.</li>\n<li>[x] Create a <code>wasmtime-collections</code> crate that exposes fallible <code>Vec</code>, <code>HashMap</code>, etc... This is probably just going to be newtypes over the types we already use today, but <code>wasmtime_collections::Vec::push</code> will return a <code>Result</code> and be implemented via something like <code>self.0.try_reserve(1)?; self.0.push(item); Ok(())</code>, for example.</li>\n<li>[x] We will need custom <code>serde::Deserialize</code> implementations that handle OOM failure for the <code>wasmtime-collections</code> types we use in our metadata that gets serialized into elf sections in our compiled code.</li>\n<li>[ ] We would ideally like to statically analyze our code and make sure that we aren't allocating infallibly in the relevant code paths. It seems like we can probably use clippy for this, or at least for a 95% solution to this that is Good Enough in practice.</li>\n<li>[ ] We need a way to dynamically test/fuzz our OOM handling to make sure we are actually getting it right in practice.</li>\n</ul>\n<p>We will initially focus on supporting the following code paths:</p>\n<ul>\n<li>Creating a <code>Config</code></li>\n<li>Creating an <code>Engine</code></li>\n<li>Creating a <code>Linker</code></li>\n<li>Creating <code>InstancePre</code>s</li>\n<li>Deserializing pre-compiled <code>Module</code>s and <code>Component</code>s (<em>not</em> compiling new ones!)</li>\n<li>Creating <code>Store</code>s</li>\n<li>Creating <code>Instance</code>s</li>\n<li>Creating <code>Memory</code>s, <code>Table</code>s, <code>Global</code>s, etc...</li>\n<li>Running Wasm</li>\n</ul>\n<p>Basically, everything that is supported in our no-std/pulley builds now: a basic runtime without the compiler, that can only run pre-compiled Wasm. We will not initially support async or the pooling allocator either, for example. I have vague ideas about how we might be able to refactor the pooling allocator for greater flexibility and enable its use in no-std / no-virtual-memory environments, but that is a bit orthogonal.</p>\n<p>Eventually we will want to support async Wasm, yielding on out-of-fuel, ..., and the component model's async functionality. That is going to be a larger project on top of this already large project, so I'm going to delay talking about how we will cross that bridge until we get closer to it.</p>\n<p>In practice, I expect that we will start with the OOM testing/fuzzing, create something very simple that fails immediately, and land that as \"expected to fail\". Then we can get that passing, which will be quite a bunch of work for this first iteration. Then we can remove the failure expectation. Then we can do a little bit more stuff inside the OOM testing/fuzzing and reveal new places we need to fix, and then we can fix those. We can continue this process until things are starting to look more and more complete. At some point we will add the clippy lints, initially to smaller modules and eventually to bigger regions of code. But the testing can be the forcing function for what area of code we add OOM handling to each step of the way.</p>\n<p>The best way to dynamically test/fuzz OOM handling that I know of is <a href=\"https://firefox-source-docs.mozilla.org/js/hacking_tips.html#how-to-debug-oomtest-failures\">the approach taken by SpiderMonkey's <code>oomTest()</code> helper</a>: run a piece of code (potentially written by humans or generated by a fuzzer) with a special allocator that will return null on the first allocation made and check that the code didn't fail to handle the OOM, then run that code again but failing on the second allocation, then the third, etc... up to your time/compute budget. Starting by building this infrastructure is my rough plan. I've done a little bit of digging for other approaches to ensuring that your OOM-handling is correct, and I haven't really found anything, just people arguing about whether you should even check for null returns from <code>malloc</code> or not, which is not very helpful. That is to say, if anyone has any other ideas or knows of any other prior art here, I'd love to hear about it!</p>\n</blockquote>",
        "id": 573164305,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1770763288
    },
    {
        "content": "<p>fitzgen edited <a href=\"https://github.com/bytecodealliance/wasmtime/issues/12069\">issue #12069</a>:</p>\n<blockquote>\n<p>We have been discussing this in a couple recent Wasmtime meetings[^0] and <a href=\"#narrow/channel/217126-wasmtime/topic/OOM.20handling.20in.20.28parts.20of.29.20Wasmtime\">on Zulip</a> and I figured it was time to centralize discussion in a tracking issue.</p>\n<p>[^0]: See <a href=\"https://github.com/bytecodealliance/meetings/blob/main/wasmtime/2025/wasmtime-10-23.md\">https://github.com/bytecodealliance/meetings/blob/main/wasmtime/2025/wasmtime-10-23.md</a> and <a href=\"https://github.com/bytecodealliance/meetings/blob/main/wasmtime/2025/wasmtime-11-20.md\">https://github.com/bytecodealliance/meetings/blob/main/wasmtime/2025/wasmtime-11-20.md</a></p>\n<p>What does handling OOM mean in this case? It means turning allocation failure into an <code>Err(...)</code> return and ultimately propagating that up to the Wasmtime embedder. It may even involve poisoning various data structures if necessary, maybe up to a whole store if necessary, but we haven't fleshed out the details completely yet. That will happen in discussions on this issue and various PRs during implementation.</p>\n<p>Various, unordered sketches of things that will be involved:</p>\n<ul>\n<li>[x] Replace <code>anyhow::Error</code> with a custom <code>wasmtime::Error</code>. At its most bare-bones, with all cargo features disabled, we will want this to basically be an <code>enum</code> without any data payloads in its variants. As we enable more cargo features, we can start adding support for formatting and error context and ultimately get to something like <code>anyhow::Error</code> with all features enabled.</li>\n<li>[x] Create a <code>wasmtime-collections</code> crate that exposes fallible <code>Vec</code>, <code>HashMap</code>, etc... This is probably just going to be newtypes over the types we already use today, but <code>wasmtime_collections::Vec::push</code> will return a <code>Result</code> and be implemented via something like <code>self.0.try_reserve(1)?; self.0.push(item); Ok(())</code>, for example.</li>\n<li>[x] We will need custom <code>serde::Deserialize</code> implementations that handle OOM failure for the <code>wasmtime-collections</code> types we use in our metadata that gets serialized into elf sections in our compiled code.</li>\n<li>[ ] We would ideally like to statically analyze our code and make sure that we aren't allocating infallibly in the relevant code paths. It seems like we can probably use clippy for this, or at least for a 95% solution to this that is Good Enough in practice.</li>\n<li>[ ] We need a way to dynamically test/fuzz our OOM handling to make sure we are actually getting it right in practice.</li>\n</ul>\n<p>We will initially focus on supporting the following code paths:</p>\n<ul>\n<li>[x] Creating a <code>Config</code></li>\n<li>[x] Creating an <code>Engine</code></li>\n<li>[x] Creating a <code>Linker</code></li>\n<li>[ ] Creating <code>InstancePre</code>s</li>\n<li>[ ] Deserializing pre-compiled <code>Module</code>s and <code>Component</code>s (<em>not</em> compiling new ones!)</li>\n<li>[x] Creating <code>Store</code>s</li>\n<li>[ ] Creating <code>Instance</code>s</li>\n<li>[ ] Creating <code>Memory</code>s</li>\n<li>[ ] Creating <code>Table</code>s</li>\n<li>[ ] Creating <code>Global</code>s</li>\n<li>[ ] Creating <code>Func</code>s</li>\n<li>[ ] Running Wasm</li>\n</ul>\n<p>Basically, everything that is supported in our no-std/pulley builds now: a basic runtime without the compiler, that can only run pre-compiled Wasm. We will not initially support async or the pooling allocator either, for example. I have vague ideas about how we might be able to refactor the pooling allocator for greater flexibility and enable its use in no-std / no-virtual-memory environments, but that is a bit orthogonal.</p>\n<p>Eventually we will want to support async Wasm, yielding on out-of-fuel, ..., and the component model's async functionality. That is going to be a larger project on top of this already large project, so I'm going to delay talking about how we will cross that bridge until we get closer to it.</p>\n<p>In practice, I expect that we will start with the OOM testing/fuzzing, create something very simple that fails immediately, and land that as \"expected to fail\". Then we can get that passing, which will be quite a bunch of work for this first iteration. Then we can remove the failure expectation. Then we can do a little bit more stuff inside the OOM testing/fuzzing and reveal new places we need to fix, and then we can fix those. We can continue this process until things are starting to look more and more complete. At some point we will add the clippy lints, initially to smaller modules and eventually to bigger regions of code. But the testing can be the forcing function for what area of code we add OOM handling to each step of the way.</p>\n<p>The best way to dynamically test/fuzz OOM handling that I know of is <a href=\"https://firefox-source-docs.mozilla.org/js/hacking_tips.html#how-to-debug-oomtest-failures\">the approach taken by SpiderMonkey's <code>oomTest()</code> helper</a>: run a piece of code (potentially written by humans or generated by a fuzzer) with a special allocator that will return null on the first allocation made and check that the code didn't fail to handle the OOM, then run that code again but failing on the second allocation, then the third, etc... up to your time/compute budget. Starting by building this infrastructure is my rough plan. I've done a little bit of digging for other approaches to ensuring that your OOM-handling is correct, and I haven't really found anything, just people arguing about whether you should even check for null returns from <code>malloc</code> or not, which is not very helpful. That is to say, if anyone has any other ideas or knows of any other prior art here, I'd love to hear about it!</p>\n</blockquote>",
        "id": 573618617,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1770930944
    }
]