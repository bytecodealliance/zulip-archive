[
    {
        "content": "<p><strong>ANtutov</strong> requested <a href=\"https://github.com/orgs/bytecodealliance/teams/wasmtime-wasi-reviewers\">wasmtime-wasi-reviewers</a> for a review on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/12490\">PR #12490</a>.</p>",
        "id": 571480667,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1770051110
    },
    {
        "content": "<p>ANtutov opened <a href=\"https://github.com/bytecodealliance/wasmtime/pull/12490\">PR #12490</a> from <code>ANtutov:perf/wasi-nn-tensor-bytes</code> to <code>bytecodealliance:main</code>:</p>\n<blockquote>\n<p>&lt;!-- Why these changes? --&gt;<br>\nPreviously the helper functions converting between Vec&lt;f32&gt; and Vec&lt;u8&gt; allocated intermediate vectors and iterated over the data twice, adding unnecessary overhead for large tensors and example code.</p>\n<p>&lt;!-- What is changed? --&gt;<br>\nReimplemented f32_vec_to_bytes and bytes_to_f32_vec (and their copies in the ONNX and WinML examples) to build the output vectors in a single pass without temporary collections, while preserving little-endian encoding and the existing panic behavior on invalid input lengths.</p>\n</blockquote>",
        "id": 571480668,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1770051110
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/pull/12490#issuecomment-3836993709\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/12490\">PR #12490</a>:</p>\n<blockquote>\n<p>cc @rahulchaphalkar @jlb6740 </p>\n</blockquote>",
        "id": 571501915,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1770057678
    }
]