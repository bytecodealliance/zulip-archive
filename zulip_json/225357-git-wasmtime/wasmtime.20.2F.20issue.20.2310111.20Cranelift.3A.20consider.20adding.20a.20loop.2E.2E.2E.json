[
    {
        "content": "<p><a href=\"https://github.com/fitzgen\">fitzgen</a> added the cranelift<span aria-label=\"goal\" class=\"emoji emoji-1f945\" role=\"img\" title=\"goal\">:goal:</span>optimize-speed label to <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10111\">Issue #10111</a>.</p>",
        "id": 495812154,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1737763040
    },
    {
        "content": "<p><a href=\"https://github.com/fitzgen\">fitzgen</a> added the cranelift label to <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10111\">Issue #10111</a>.</p>",
        "id": 495812155,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1737763040
    },
    {
        "content": "<p>fitzgen opened <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10111\">issue #10111</a>:</p>\n<blockquote>\n<p>That is, a pass that unrolls one iteration of the loop body just before the actual loop. This is often beneficial because loop bodies might contain conditional code that only executes on the first iteration.</p>\n<p>There could be additional benefit for Cranelift in particular: right now, Cranelift will deduplicate various kinds side-effecting-but-idempotent instructions (such as <code>trapz</code>s) but will not move those instructions outside of their original blocks and hoist them just above the loop even when it would be valid to do so. But if we have already unrolled the first iteration of a loop, then that unrolled first iteration will dominate the rest of the loop and when we dedupe those instructions from inside the loop body to their unrolled counterparts, we are effectively doing exactly that code motion we wanted to do before but could not.</p>\n<p>Random tidbits:</p>\n<ul>\n<li>\n<p>Could we do this at the same time as the aegraphs pass? I <em>think</em> so? But it would be in the same traversal, not actually in ISLE, similar to eg the alias analysis optimization.</p>\n</li>\n<li>\n<p>We will need some heuristics for when to peel loops or not. Don't think we want the code bloat of peeling every single loop in the whole program. Maybe just innermost loops? Maybe just loops of up to a certain size? Lots of experimenting to be done in this regard.</p>\n</li>\n</ul>\n</blockquote>",
        "id": 495812158,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1737763040
    },
    {
        "content": "<p>fitzgen <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10111#issuecomment-2613625358\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10111\">issue #10111</a>:</p>\n<blockquote>\n<p>If we don't care about cleaning up conditional code that only happens in the first iteration of the loop, and can statically be shown as such after the peeling, and we only care about being able to LICM side-effectful-but-idempotent instructions, then we could also just investigate extending aegraph elaboration to support LICM'ing the idempotent parts of the side-effectful skeleton when that wouldn't move one side-effectful instruction across another one. But that kinda feels a little too specific and one-off for my tastes, in comparison to the peeling which effectively gives us that and also some more stuff all at once (ie is more general/powerful and probably not very different in terms of engineering effort?).</p>\n</blockquote>",
        "id": 495812591,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1737763300
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10111#issuecomment-2613643923\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10111\">issue #10111</a>:</p>\n<blockquote>\n<p>I'd be interested in working through some example IR you've see to motivate this -- the main reason being that my preference is actually the opposite, toward better LICM rather than general peeling. The main reasons are that:</p>\n<ul>\n<li>Peeling doubles the size of the loop (in the general case), as you mention in your second bullet point; that seems to me like it will be the dominant negative effect and a large one. Consider the two universes we could choose with our heuristics:<ul>\n<li>We peel only inner loops or small loops, as suggested. Then any benefit of hoisting traps happens only for some code in the program; and there are surprising performance cliffs that occur. (Adding a few instructions causes the whole loop to slow significantly; adding another nested loop somewhere turns the main loop into \"not an inner loop anymore\".) This seems generally contrary to the \"predictable performance\" design goal of Wasm and by extension of Cranelift.</li>\n<li>We peel all loops. Then we have significant code expansion, and compile time slowdown: somewhere between 1x and 2x depending on how much of a program's body lives in loops. (Or more, depending on how we handle nested loops.) Note that will also turn into runtime slowdown if there is any icache presure.</li>\n</ul>\n</li>\n<li>Peeling is a pretty complex change to the aegraph visitor pass; it breaks some fundamental invariants and adds a new dimension of complexity (output CFG is not input CFG, with all the associated implications for SSA, the domtree, and otherwise).</li>\n<li>The main benefit on its own is LICM-for-free (but then at the cost of a doubling of code size); additional benefits, like specializations for the first iteration, require other work like branch folding which we don't do at all currently. We could revisit peeling when we do branch folding as both are control flow/code motion optimizations.</li>\n</ul>\n<p>In contrast, \"better LICM\" feels much more tractable to me: it doesn't require bulk CFG manipulation (only instruction placement/scheduling which we're already doing) and gets the same concrete benefits on e.g. repeated trap checks without paying the large associated cost (duplicating the loop body).</p>\n</blockquote>",
        "id": 495814224,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1737764443
    },
    {
        "content": "<p>fitzgen <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10111#issuecomment-2619716825\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10111\">issue #10111</a>:</p>\n<blockquote>\n<blockquote>\n<p>I'd be interested in working through some example IR you've see to motivate this</p>\n</blockquote>\n<p>This is something @alexcrichton would have to share, as I believe what I saw was a snippet from when he was diving into some benchmark's preformance on Pulley.</p>\n<blockquote>\n<p>my preference is actually the opposite, toward better LICM rather than general peeling</p>\n</blockquote>\n<p>You bring up very fair points. I'm definitely not set in my opinion.</p>\n<p>I guess peeling+GVN feels clean to me because we \"just\" add a little peeling and then a bunch of desirable properties fall out \"for free\". In comparison, improving the LICM for this case is basically adding a bunch of new checks for special cases and otherwise-unshared, manual IR manipulation code.</p>\n<p>The other complication with improving LICM is that we don't necessarily have a single block dominating the loop but also that will only be executed if the loop will iterate at least once. We require such a block for the LICM, lest we introduce partially redundant code. We could, of course, ensure that such a block exists, inserting one if it is missing, but this is the kind of one-off, otherwise-unshared, manual IR manipulation that I prefer to avoid when possible... It also has the same CFG complexity as peeling with regards to aegraph pass integration.</p>\n<p>I agree that code bloat is the biggest concern with peeling, and I don't have any silver bullet there. This may indeed outweigh everything else.</p>\n</blockquote>",
        "id": 496394836,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1738087508
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10111#issuecomment-2619812899\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10111\">issue #10111</a>:</p>\n<blockquote>\n<p>Hmm, yeah, we do need preheaders (\"single block dominating the loop\") for the hoisting to be guaranteed in an LICM world. I guess our LICM today is incomplete/\"best effort\" in this way today as well: if we don't have a place to hoist to then we won't hoist. I <em>think</em> we get the proper block separation as a side-effect of the Wasm-to-CLIF translation, so in practice this may not matter for Wasm workloads, but that's an emergent property rather than a well-modularized guarantee so I agree it doesn't feel great.</p>\n<blockquote>\n<p>a bunch of new checks for special cases and otherwise-unshared, manual IR manipulation code.</p>\n</blockquote>\n<p>I guess my hope at least had been that we would extend the instruction predicates we have currently -- \"pure\", \"idempotent\" and the like. But actually when hoisting a side-effect we need to know that it won't cross any other side-effects so that does involve a sort of ad-hoc scan of the loop body and reasoning about side-effect colors.</p>\n<p>... and now I think I'm coming around to the peeling side at least for the <code>trapz</code> case -- it does indeed feel like the most principled way of reasoning about side-effect motion given the above. Well, the code-bloat is a quantitative question -- we can evaluate that. Maybe what we could focus on is coming up with stable (\"cliff-free\") heuristics -- e.g., always peel if conditional trap instructions are present. Maybe we could also build this in tandem with some sort of redundancy elimination -- duplicate-block merging? -- that could clean up cases where we didn't get any benefit.</p>\n</blockquote>",
        "id": 496403398,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1738090309
    },
    {
        "content": "<p>fitzgen <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10111#issuecomment-2619895116\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10111\">issue #10111</a>:</p>\n<blockquote>\n<blockquote>\n<p>I _think_ we get the proper block separation as a side-effect of the Wasm-to-CLIF translation, so in practice this may not matter for Wasm workloads</p>\n</blockquote>\n<p>I am not sure about our specific Wasm-to-CLIF translation either, but I do not believe that Wasm's <code>loop</code> construct provides this guarantee.</p>\n<blockquote>\n<p>Maybe what we could focus on is coming up with stable (\"cliff-free\") heuristics -- e.g., always peel if conditional trap instructions are present.</p>\n</blockquote>\n<p>FWIW, the case I am remembering might have actually been a trusted load of something in the vmctx (heap base?) and not actually a conditional trap instruction. I don't think that changes anything we've been discussing tho.</p>\n<p>Anyways, another \"cliff-free\" (not to be confused with CLIF-free!) heuristic would be to always and only peel innermost loops, probably in combination with something like \"and if there is a trusted load or an idempotent side-effectful instruction in the loop body\". If we didn't want to invest in subsequent passes to clean up any accidental redundancy, we could refine the heuristics even further with things like \"and the instruction we are targeting for LICM via peeling doesn't depend on a block parameter defined within the loop.\"</p>\n<blockquote>\n<p>Maybe we could also build this in tandem with some sort of redundancy elimination -- duplicate-block merging? -- that could clean up cases where we didn't get any benefit.</p>\n</blockquote>\n<p>That would indeed be cool, although more work also so I wouldn't argue that we should block landing a hypothetical peeling pass on this existing too, unless the numbers show that bloat is unacceptable. Are you imagining that this would do some kind of renumbering to dedupe block params as well? Like, would you expect it to clean up the following duplicate blocks?</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"n\">block1</span><span class=\"p\">(</span><span class=\"n\">v10</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"kt\">i32</span><span class=\"p\">):</span>\n<span class=\"w\">  </span><span class=\"nc\">v11</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">iadd_imm</span><span class=\"w\"> </span><span class=\"n\">v10</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"mi\">1</span>\n<span class=\"w\">  </span><span class=\"n\">store</span><span class=\"w\"> </span><span class=\"n\">v11</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">v456</span>\n<span class=\"w\">  </span><span class=\"n\">jump</span><span class=\"w\"> </span><span class=\"n\">block789</span>\n\n<span class=\"n\">block2</span><span class=\"p\">(</span><span class=\"n\">v12</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"kt\">i32</span><span class=\"p\">):</span>\n<span class=\"w\">  </span><span class=\"nc\">v13</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">iadd_imm</span><span class=\"w\"> </span><span class=\"n\">v12</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"mi\">1</span>\n<span class=\"w\">  </span><span class=\"n\">store</span><span class=\"w\"> </span><span class=\"n\">v12</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">v456</span>\n<span class=\"w\">  </span><span class=\"n\">jump</span><span class=\"w\"> </span><span class=\"n\">block789</span>\n</code></pre></div>\n<p>I guess we can start simple and then add more complexity if needed.</p>\n</blockquote>",
        "id": 496410649,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1738092900
    }
]