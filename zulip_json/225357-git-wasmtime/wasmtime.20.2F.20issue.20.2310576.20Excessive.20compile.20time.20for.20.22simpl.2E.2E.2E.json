[
    {
        "content": "<p>alexcrichton opened <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10576\">issue #10576</a>:</p>\n<blockquote>\n<p>OSS-Fuzz has had an <a href=\"https://oss-fuzz.com/testcase-detail/4971399285899264\">open bug for this</a> for quite some time but I'm only just now getting around to filing an issue about this. The gist of the fuzz bug is that Wasmtime times out in the <code>compile</code> test target where the only thing that target does is compile a module. A timeout here means that the 60s time limit is exceeded, and the time limit here is with sanitizers and parallelism disabled on OSS-Fuzz infrastructure. This can be roughly approximated by running locally in release mode with <code>-Cparallel-compilation=n</code> and multiplying the result by ~30.</p>\n<p>The module in question is:</p>\n<div class=\"codehilite\" data-code-language=\"wasm\"><pre><span></span><code>(module\n    (func)\n    (func)\n    ;; ... 119248 times ...\n    (func)\n)\n</code></pre></div>\n<p>aka this is just a giant module of a lot of empty functions. <a href=\"https://github.com/user-attachments/files/19739342/foo.wasm.gz\">foo.wasm.gz</a> is the compresed version of this module.</p>\n<p>Locally I see:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"cp\">$</span><span class=\"w\"> </span><span class=\"n\">time</span><span class=\"w\"> </span><span class=\"n\">wasmtime</span><span class=\"w\"> </span><span class=\"n\">compile</span><span class=\"w\"> </span><span class=\"o\">-</span><span class=\"n\">C</span><span class=\"w\"> </span><span class=\"n\">parallel</span><span class=\"o\">-</span><span class=\"n\">compilation</span><span class=\"o\">=</span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"n\">foo</span><span class=\"p\">.</span><span class=\"n\">wasm</span>\n<span class=\"n\">wasmtime</span><span class=\"w\"> </span><span class=\"n\">compile</span><span class=\"w\"> </span><span class=\"o\">-</span><span class=\"n\">C</span><span class=\"w\"> </span><span class=\"n\">parallel</span><span class=\"o\">-</span><span class=\"n\">compilation</span><span class=\"o\">=</span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"n\">foo</span><span class=\"p\">.</span><span class=\"n\">wasm</span><span class=\"w\">  </span><span class=\"mf\">1.05</span><span class=\"n\">s</span><span class=\"w\"> </span><span class=\"n\">user</span><span class=\"w\"> </span><span class=\"mf\">0.15</span><span class=\"n\">s</span><span class=\"w\"> </span><span class=\"n\">system</span><span class=\"w\"> </span><span class=\"mi\">99</span><span class=\"o\">%</span><span class=\"w\"> </span><span class=\"n\">cpu</span><span class=\"w\"> </span><span class=\"mf\">1.205</span><span class=\"w\"> </span><span class=\"n\">total</span>\n</code></pre></div>\n<p>which, for being a bunch of empty functions, is quite a lot! There's a lot of functions in this module but 10 microseconds for an empty function feels a bit excessive regardless. While optimizing this probably won't help out too too much in the long term, it's perhaps worthwhile to still try to improve this if not just for oss-fuzz timeouts and fuzzing.</p>\n<p>A profile of the compilation looks <a href=\"https://share.firefox.dev/4ikGBoK\">like this</a> which notably spends the most amount of \"self\" time in memmove. There's also notably a fair amount of allocation traffic as well. I'm not sure how to improve the regalloc2 parts myself but for memmove that I do know how to improve.</p>\n<h2>Moving <code>MachBuffer</code> less</h2>\n<p>The basic problem I've seen is that we're pretty liberal in Cranelift about moving data structures by ownership between phases, notably the <code>MachBuffer&lt;T&gt;</code>. This type is very large (lots of <code>SmallVec</code>) and is created/moved quite a lot throughout a compilation. This I believe adds up to quite a lot of memmove costs.</p>\n<p>The movements I've seen are:</p>\n<ul>\n<li><a href=\"https://github.com/bytecodealliance/wasmtime/blob/e6e03c34cfb4f616e437bfcaa67575c3ab3a2e0c/cranelift/codegen/src/machinst/buffer.rs#L1539\"><code>MachBuffer::finish</code></a></li>\n<li><a href=\"https://github.com/bytecodealliance/wasmtime/blob/e6e03c34cfb4f616e437bfcaa67575c3ab3a2e0c/cranelift/codegen/src/isa/x64/mod.rs#L76-L96\"><code>TargetIsa::compile_function</code></a></li>\n<li><a href=\"https://github.com/bytecodealliance/wasmtime/blob/e6e03c34cfb4f616e437bfcaa67575c3ab3a2e0c/cranelift/codegen/src/context.rs#L124-L143\"><code>Context::compile_stencil</code></a></li>\n<li><a href=\"https://github.com/bytecodealliance/wasmtime/blob/e6e03c34cfb4f616e437bfcaa67575c3ab3a2e0c/cranelift/codegen/src/context.rs#L203-L217\"><code>Context::compile</code></a></li>\n<li><a href=\"https://github.com/bytecodealliance/wasmtime/blob/e6e03c34cfb4f616e437bfcaa67575c3ab3a2e0c/crates/cranelift/src/compiler.rs#L725-L733\"><code>compile_uncached</code></a></li>\n<li><a href=\"https://github.com/bytecodealliance/wasmtime/blob/e6e03c34cfb4f616e437bfcaa67575c3ab3a2e0c/crates/cranelift/src/compiler.rs#L1020\"><code>Compiler::finish_with_info</code></a></li>\n</ul>\n<p>In general I don't think rustc/LLVM are even capable of eliding most of these copies which means that for each function we're copying a this very large structure ~6 times (ish). Multiply that by ~100k and the size of the structure and that's a lot of memory moving around and can probably explain at least a good portion of the second of compile time for this module.</p>\n<p>Ideally we would refactor cranelift to require much less movement of the <code>MachBuffer</code> type. In an ideal world we could even reuse <code>MachBuffer</code> structures between compiling functions too. In any case we can probably get a long-ish way restructuring things and ownership of the <code>MachBuffer</code></p>\n<h2>Other compiler structures</h2>\n<p>I've seen other compiler structures in the profile be quite large, such as <a href=\"https://github.com/bytecodealliance/wasmtime/blob/e6e03c34cfb4f616e437bfcaa67575c3ab3a2e0c/crates/cranelift/src/compiler.rs#L46-L51\"><code>CompilerContext</code></a>, which are moved around a lot. Ideally we could perhaps <code>Box</code> up some contexts and or make movements cheaper to work with.</p>\n<hr>\n<p>I'm sure there's other parts of the profile to dig in to as well, but I wanted to at least file an issue in case anyone's interested in chipping away at some pieces here.</p>\n</blockquote>",
        "id": 512126460,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1744648698
    },
    {
        "content": "<p><a href=\"https://github.com/alexcrichton\">alexcrichton</a> added the fuzz-bug label to <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10576\">Issue #10576</a>.</p>",
        "id": 512126488,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1744648708
    },
    {
        "content": "<p><a href=\"https://github.com/alexcrichton\">alexcrichton</a> added the cranelift<span aria-label=\"goal\" class=\"emoji emoji-1f945\" role=\"img\" title=\"goal\">:goal:</span>compile-time label to <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10576\">Issue #10576</a>.</p>",
        "id": 512126489,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1744648708
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10576#issuecomment-2803479818\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10576\">issue #10576</a>:</p>\n<blockquote>\n<p>The intent of <code>MachBuffer</code>'s inline <code>SmallVec</code>s was to avoid any allocations at all when on-stack, moved not at all or only once, and used for small-to-medium-sized functions, but that was a very speculative benefit when we sketched out the new backend framework in 2020, and it looks likely that refactors and added complexity through the years have adapted to moving it around liberally (as is more idiomatic).</p>\n<p>Perhaps a simple fix could be to <code>Box</code> it up? Alternately we convert all the <code>SmallVec</code>s to <code>Vec</code>s. I don't have the cycles to try and benchmark either at the moment -- this is just to say that there's no reason we should be wedded to the current approach other than legacy...</p>\n</blockquote>",
        "id": 512202571,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1744680180
    }
]