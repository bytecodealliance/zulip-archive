[
    {
        "content": "<p>cfallin opened <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10150\">issue #10150</a>:</p>\n<blockquote>\n<p>Today in the Wasm-to-CLIF translator we have a <a href=\"https://github.com/bytecodealliance/wasmtime/blob/facc9925242cad47df3d9910afd2a552e196c7f7/crates/cranelift/src/translate/code_translator/bounds_checks.rs#L1\">detailed set of cases</a> by which we break down Wasm-level loads and stores into statically or dynamically bounds-checked operations. For example, a fully general dynamic bounds check becomes something like:</p>\n<ul>\n<li>Compute the Wasm index value (<code>i32</code>) plus offset given on the load;</li>\n<li>Compute that Wasm address plus the access size;</li>\n<li>Compare that end-of-access address to a loaded memory size/bound;</li>\n<li>Trap if out-of-bounds;</li>\n<li>Add the loaded memory base to the index plus offset;</li>\n<li>Load from that computed host address.</li>\n</ul>\n<p>With variations possible depending on exactly what guard regions exist, whether Spectre mitigations are enabled (cmoves-of-null-pointers rather than branches for traps), whether the address is constant and known in-bounds, whether the access is 1 byte or multiple, and all the rest.</p>\n<p>The theory behind \"exploding\" the Wasm-level operation into constituent parts in CLIF is twofold. First, it allows the compiler backends to deal with a simpler \"core IR\" that knows only about host loads and stores -- there is no need to have a concept of separate bounds-checked address spaces baked into every backend, and all the backends benefit from one central encoding of all the special cases and optimizations. Second, it was thought that this might allow some parts to be optimized: e.g., GVN when accesses have parts of the address in common (only offsets differ), or GVN and LICM when some parts are loop-invariant (e.g., base pointers on immovable memories or limits on non-growable memories), or constant folding, or maybe other things. The less we have to teach the optimizer about \"bounds check\" as a concept, the better.</p>\n<p>However, there are several more recent realizations we have had. First, the promised optimization is only partly realizable; for example, the ability for memories to grow means that limit fields must be reloaded frequently or every time. And the common deployment mode that results in dynamic bounds-checking typically has no guard region at all (\"no virtual memory\" scenarios on embedded systems, or high-density scenarios with many memories where frequent virtual memory changes on guards during memory growth might become a bottleneck). Because of this, some of the commonality is lost: e.g., in common configurations we probably won't be able to factor out the compare-and-trap/cmov from Wasm loads/stores with different offsets on the same base.</p>\n<p>Second, as @alexcrichton noted in today's Cranelift meeting, the Pulley interpreter-bytecode Cranelift backend wants to target new macro-ops that implement the Wasm bounds-check sequence. When there is interpreter overhead for every instruction, there is pressure away from \"exploded\" views of operation steps and back toward ready-made larger ops. Currently we would have to pattern-match all the various kinds of code we can generate to recover these macro-ops.</p>\n<p>Third, as I described recently in a talk about proof-carrying code, verifying the tiny pieces that make up a dynamic bounds-check sequence is extremely challenging: getting an analysis to understand all the variations is brittle and complex, and leads to surprising and un-intuitive quadratic verification behavior. A verifier ideally wants to see a bounds-check as a single operation with a verified implementation rather than a graph of operators that lose the intent.</p>\n<p>For all these reasons, I think we should consider adding a <code>bounds_check</code> operator to CLIF. Its semantics might be something like: <code>boundscheck32_or_null.i64 host_base, offset, limit, imm_offset, size</code>, where <code>host_base</code> (<code>i64</code> on 64-bit-pointer systems) is a host address of the start of a bounds-checked memory, <code>offset</code> is an <code>i32</code> offset into the memory, <code>limit</code> is an <code>i32</code> memory size, <code>imm_offset</code> is a 16-bit constant offset to add to the returned address (<code>u16</code>), and <code>size</code> <code>is the size of the access (</code>u8<code>). (These operand sizes were picked to allow the whole </code>InstructionData<code> to fit in 16 bytes: three </code>Value<code>s and 24 bits of payload. If the enum tag becomes a </code>u16<code> then we can make </code>imm_offset<code> a </code>u8<code> and still capture most cases without a separate </code>iadd` probably.)</p>\n<p>The semantics would be: if <code>offset + imm_offset + size &lt;= limit</code>, then return <code>host_base + offset + imm_offset</code>, otherwise return <code>0</code>. We could define a variant <code>..._or_trap</code> that traps instead on out-of-bounds.</p>\n<p>The important considerations in my view are:</p>\n<ul>\n<li>We should ensure that we can either encode optimizations that <code>bounds_check.rs</code> does with the new opcode, or else decide these optimizations aren't desired anymore. (Hopefully the former unless we have good data otherwise.) For example, if we <em>do</em> have a guard region, we could use the bounds-check opcode to compute a base without the specific load offset, then put the load offset on the machine load instruction. The Pulley backend should be able to combine these still and the verifier should be able to reason about valid ranges too.</li>\n<li>We should ensure that we aren't removing important GVN-ability. Notably the above still externalizes the loads of base and limit; so whatever we do to allow those to be readonly, LICM them out of loops, etc., still applies. Also, this opcode would be either pure (Spectre/null variant) or idempotent (trapping variant) so to the extent that we can factor out offsets as above, it should be combinable.</li>\n</ul>\n<p>Curious what others think -- any requirements this is missing? Any other important optimizations we would lose out on?</p>\n</blockquote>",
        "id": 496634772,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1738181323
    },
    {
        "content": "<p>cfallin edited <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10150\">issue #10150</a>:</p>\n<blockquote>\n<p>Today in the Wasm-to-CLIF translator we have a <a href=\"https://github.com/bytecodealliance/wasmtime/blob/facc9925242cad47df3d9910afd2a552e196c7f7/crates/cranelift/src/translate/code_translator/bounds_checks.rs#L1\">detailed set of cases</a> by which we break down Wasm-level loads and stores into statically or dynamically bounds-checked operations. For example, a fully general dynamic bounds check becomes something like:</p>\n<ul>\n<li>Compute the Wasm index value (<code>i32</code>) plus offset given on the load;</li>\n<li>Compute that Wasm address plus the access size;</li>\n<li>Compare that end-of-access address to a loaded memory size/bound;</li>\n<li>Trap if out-of-bounds;</li>\n<li>Add the loaded memory base to the index plus offset;</li>\n<li>Load from that computed host address.</li>\n</ul>\n<p>With variations possible depending on exactly what guard regions exist, whether Spectre mitigations are enabled (cmoves-of-null-pointers rather than branches for traps), whether the address is constant and known in-bounds, whether the access is 1 byte or multiple, and all the rest.</p>\n<p>The theory behind \"exploding\" the Wasm-level operation into constituent parts in CLIF is twofold. First, it allows the compiler backends to deal with a simpler \"core IR\" that knows only about host loads and stores -- there is no need to have a concept of separate bounds-checked address spaces baked into every backend, and all the backends benefit from one central encoding of all the special cases and optimizations. Second, it was thought that this might allow some parts to be optimized: e.g., GVN when accesses have parts of the address in common (only offsets differ), or GVN and LICM when some parts are loop-invariant (e.g., base pointers on immovable memories or limits on non-growable memories), or constant folding, or maybe other things. The less we have to teach the optimizer about \"bounds check\" as a concept, the better.</p>\n<p>However, there are several more recent realizations we have had. First, the promised optimization is only partly realizable; for example, the ability for memories to grow means that limit fields must be reloaded frequently or every time. And the common deployment mode that results in dynamic bounds-checking typically has no guard region at all (\"no virtual memory\" scenarios on embedded systems, or high-density scenarios with many memories where frequent virtual memory changes on guards during memory growth might become a bottleneck). Because of this, some of the commonality is lost: e.g., in common configurations we probably won't be able to factor out the compare-and-trap/cmov from Wasm loads/stores with different offsets on the same base.</p>\n<p>Second, as @alexcrichton noted in today's Cranelift meeting, the Pulley interpreter-bytecode Cranelift backend wants to target new macro-ops that implement the Wasm bounds-check sequence. When there is interpreter overhead for every instruction, there is pressure away from \"exploded\" views of operation steps and back toward ready-made larger ops. Currently we would have to pattern-match all the various kinds of code we can generate to recover these macro-ops.</p>\n<p>Third, as I described recently in a talk about proof-carrying code, verifying the tiny pieces that make up a dynamic bounds-check sequence is extremely challenging: getting an analysis to understand all the variations is brittle and complex, and leads to surprising and un-intuitive quadratic verification behavior. A verifier ideally wants to see a bounds-check as a single operation with a verified implementation rather than a graph of operators that lose the intent.</p>\n<p>For all these reasons, I think we should consider adding a <code>bounds_check</code> operator to CLIF. Its semantics might be something like: <code>boundscheck32_or_null.i64 host_base, offset, limit, imm_offset, size</code>, where <code>host_base</code> (<code>i64</code> on 64-bit-pointer systems) is a host address of the start of a bounds-checked memory, <code>offset</code> is an <code>i32</code> offset into the memory, <code>limit</code> is an <code>i32</code> memory size, <code>imm_offset</code> is a 16-bit constant offset to add to the returned address (<code>u16</code>), and <code>size</code> is the size of the access (<code>u8</code>). (These operand sizes were picked to allow the whole <code>InstructionData</code> to fit in 16 bytes: three <code>Value</code>s and 24 bits of payload. If the enum tag becomes a <code>u16</code> then we can make <code>imm_offset</code> a <code>u8</code> and still capture most cases without a separate <code>iadd</code> probably.)</p>\n<p>The semantics would be: if <code>offset + imm_offset + size &lt;= limit</code>, then return <code>host_base + offset + imm_offset</code>, otherwise return <code>0</code>. We could define a variant <code>..._or_trap</code> that traps instead on out-of-bounds.</p>\n<p>The important considerations in my view are:</p>\n<ul>\n<li>We should ensure that we can either encode optimizations that <code>bounds_check.rs</code> does with the new opcode, or else decide these optimizations aren't desired anymore. (Hopefully the former unless we have good data otherwise.) For example, if we <em>do</em> have a guard region, we could use the bounds-check opcode to compute a base without the specific load offset, then put the load offset on the machine load instruction. The Pulley backend should be able to combine these still and the verifier should be able to reason about valid ranges too.</li>\n<li>We should ensure that we aren't removing important GVN-ability. Notably the above still externalizes the loads of base and limit; so whatever we do to allow those to be readonly, LICM them out of loops, etc., still applies. Also, this opcode would be either pure (Spectre/null variant) or idempotent (trapping variant) so to the extent that we can factor out offsets as above, it should be combinable.</li>\n</ul>\n<p>Curious what others think -- any requirements this is missing? Any other important optimizations we would lose out on?</p>\n</blockquote>",
        "id": 496634895,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1738181377
    },
    {
        "content": "<p>cfallin edited <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10150\">issue #10150</a>:</p>\n<blockquote>\n<p>Today in the Wasm-to-CLIF translator we have a <a href=\"https://github.com/bytecodealliance/wasmtime/blob/facc9925242cad47df3d9910afd2a552e196c7f7/crates/cranelift/src/translate/code_translator/bounds_checks.rs#L1\">detailed set of cases</a> by which we break down Wasm-level loads and stores into statically or dynamically bounds-checked operations. For example, a fully general dynamic bounds check becomes something like:</p>\n<ul>\n<li>Compute the Wasm index value (<code>i32</code>) plus offset given on the load;</li>\n<li>Compute that Wasm address plus the access size;</li>\n<li>Compare that end-of-access address to a loaded memory size/bound;</li>\n<li>Trap if out-of-bounds;</li>\n<li>Add the loaded memory base to the index plus offset;</li>\n<li>Load from that computed host address.</li>\n</ul>\n<p>With variations possible depending on exactly what guard regions exist, whether Spectre mitigations are enabled (cmoves-of-null-pointers rather than branches for traps), whether the address is constant and known in-bounds, whether the access is 1 byte or multiple, and all the rest.</p>\n<p>The theory behind \"exploding\" the Wasm-level operation into constituent parts in CLIF is twofold. First, it allows the compiler backends to deal with a simpler \"core IR\" that knows only about host loads and stores -- there is no need to have a concept of separate bounds-checked address spaces baked into every backend, and all the backends benefit from one central encoding of all the special cases and optimizations. Second, it was thought that this might allow some parts to be optimized: e.g., GVN when accesses have parts of the address in common (only offsets differ), or GVN and LICM when some parts are loop-invariant (e.g., base pointers on immovable memories or limits on non-growable memories), or constant folding, or maybe other things. The less we have to teach the optimizer about \"bounds check\" as a concept, the better.</p>\n<p>However, there are several more recent realizations we have had. First, the promised optimization is only partly realizable; for example, the ability for memories to grow means that limit fields must be reloaded frequently or every time. And the common deployment mode that results in dynamic bounds-checking typically has no guard region at all (\"no virtual memory\" scenarios on embedded systems, or high-density scenarios with many memories where frequent virtual memory changes on guards during memory growth might become a bottleneck). Because of this, some of the commonality is lost: e.g., in common configurations we probably won't be able to factor out the compare-and-trap/cmov from Wasm loads/stores with different offsets on the same base.</p>\n<p>Second, as @alexcrichton noted in today's Cranelift meeting, the Pulley interpreter-bytecode Cranelift backend wants to target new macro-ops that implement the Wasm bounds-check sequence. When there is interpreter overhead for every instruction, there is pressure away from \"exploded\" views of operation steps and back toward ready-made larger ops. Currently we would have to pattern-match all the various kinds of code we can generate to recover these macro-ops.</p>\n<p>Third, as I described recently in a talk about proof-carrying code, verifying the tiny pieces that make up a dynamic bounds-check sequence is extremely challenging: getting an analysis to understand all the variations is brittle and complex, and leads to surprising and un-intuitive quadratic verification behavior. A verifier ideally wants to see a bounds-check as a single operation with a verified implementation rather than a graph of operators that lose the intent.</p>\n<p>For all these reasons, I think we should consider adding a bounds-check operator to CLIF. Its semantics might be something like: <code>boundscheck32_or_null.i64 host_base, offset, limit, imm_offset, size</code>, where <code>host_base</code> (<code>i64</code> on 64-bit-pointer systems) is a host address of the start of a bounds-checked memory, <code>offset</code> is an <code>i32</code> offset into the memory, <code>limit</code> is an <code>i32</code> memory size, <code>imm_offset</code> is a 16-bit constant offset to add to the returned address (<code>u16</code>), and <code>size</code> is the size of the access (<code>u8</code>). (These operand sizes were picked to allow the whole <code>InstructionData</code> to fit in 16 bytes: three <code>Value</code>s and 24 bits of payload. If the enum tag becomes a <code>u16</code> then we can make <code>imm_offset</code> a <code>u8</code> and still capture most cases without a separate <code>iadd</code> probably.)</p>\n<p>The semantics would be: if <code>offset + imm_offset + size &lt;= limit</code>, then return <code>host_base + offset + imm_offset</code>, otherwise return <code>0</code>. We could define a variant <code>..._or_trap</code> that traps instead on out-of-bounds.</p>\n<p>The important considerations in my view are:</p>\n<ul>\n<li>We should ensure that we can either encode optimizations that <code>bounds_check.rs</code> does with the new opcode, or else decide these optimizations aren't desired anymore. (Hopefully the former unless we have good data otherwise.) For example, if we <em>do</em> have a guard region, we could use the bounds-check opcode to compute a base without the specific load offset, then put the load offset on the machine load instruction. The Pulley backend should be able to combine these still and the verifier should be able to reason about valid ranges too.</li>\n<li>We should ensure that we aren't removing important GVN-ability. Notably the above still externalizes the loads of base and limit; so whatever we do to allow those to be readonly, LICM them out of loops, etc., still applies. Also, this opcode would be either pure (Spectre/null variant) or idempotent (trapping variant) so to the extent that we can factor out offsets as above, it should be combinable.</li>\n</ul>\n<p>Curious what others think -- any requirements this is missing? Any other important optimizations we would lose out on?</p>\n</blockquote>",
        "id": 496635000,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1738181406
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10150#issuecomment-2623210484\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10150\">issue #10150</a>:</p>\n<blockquote>\n<p>For reference <a href=\"https://github.com/bytecodealliance/wasmtime/pull/10154\">https://github.com/bytecodealliance/wasmtime/pull/10154</a> is the culmination of the work I was doing for folding pulley bounds checks/loads into one op. For me the ISLE isn't tiny but it's also not unmanagable, personally.</p>\n</blockquote>",
        "id": 496667513,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1738195566
    },
    {
        "content": "<p>fitzgen <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10150#issuecomment-2686291280\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10150\">issue #10150</a>:</p>\n<blockquote>\n<blockquote>\n<p>However, there are several more recent realizations we have had. First, the promised optimization is only partly realizable; for example, the ability for memories to grow means that limit fields must be reloaded frequently or every time.</p>\n</blockquote>\n<p>I would expect that alias analysis would make it so that two wasm loads/stores that do not cross a function call would indeed only load the heap limit once. Are you saying that is not the case in practice?</p>\n</blockquote>",
        "id": 502151498,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1740606951
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10150#issuecomment-2699162825\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/10150\">issue #10150</a>:</p>\n<blockquote>\n<blockquote>\n<p>I would expect that alias analysis would make it so that two wasm loads/stores that do not cross a function call would indeed only load the heap limit once. Are you saying that is not the case in practice?</p>\n</blockquote>\n<p>Ah, I may have read too much into some examples I had been looking at -- indeed it seems that limits are reused (alias analysis merges loads) between function calls.</p>\n</blockquote>",
        "id": 503380722,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1741128858
    }
]